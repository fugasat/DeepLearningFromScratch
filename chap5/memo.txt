まとめ
    NN処理では勾配法の処理に時間がかかる
        数値微分
            損失関数の微分計算に時間がかかる
        誤差逆伝播法
            微分は計算グラフの逆伝播で算出できる
                勾配法よりも計算がシンプルになる
                    重みパラメータ毎の数値微分(交差エントロピー誤差)の計算が不要になる
                        損失関数の計算数が圧倒的に少なくなる
                    数値微分
                        重み行列から１つずつパラメータを取り出し損失関数の数値微分を計算
                            1層あたりの計算数
                                損失関数の計算数 = パラメータ数 x 2(前後の値で計算) = 79520
                                    (39200(W1) + 50(b1) + 500(W2) + 10(b1)) x 2 = 79520
                                その他 = パラメータ数 x 1(数値微分：前後損失関数の中間値を取得)
                    誤差逆伝播法
                        重み行列に対して、内積x2と加算x1だけで計算できる
                            1層あたりの計算数 = 2
                                損失関数の計算数 = 1
                                その他=パラメータ数 x 3(内積x2と加算x1) ※行列単位の計算なので高速に処理できる

-------------------------------------

ReLU vs Sigmoid
    ReLUの方が精度が高いが処理速度は劣る
    ReLU
        最終epoch
            loss : 0.0888871460512882
            train_acc : 0.9781666666666666 / test_acc : 0.9661
        実行速度 : 58sec
    Sigmoid
        最終epoch
            loss : 0.2196875570339384
            train_acc : 0.9476333333333333 / test_acc : 0.9468
        実行速度 : 55sec

dout = 1(初期値)の意味
    初期値のdout使ってない…

バイアスの調整の意味は？
    常にdb(バイアスの微分)=0の場合でも結果はあまり変わらない
        loss : 0.06776236252266846
        train_acc : 0.9783666666666667 / test_acc : 0.9667

-------------------------------------

y = ax + b
    上流からの微分：dL / dy

NNの順伝搬で行う行列の内積＝アフィン変換

アフィン変換
幾何学の分野で、ある図形を回転させたり引き延ばしたりする変換をアフィン変換と呼ぶ。
　→　アフィン変換＝平行移動＋線形変換

Softmax
    出力値（スコア）を確率に変換（0-1に正規化）
        Softmaxは学習時に利用
        出力層ではどのパラメータが最大になるのか見るだけなのでSoftmaxは省略する

Softmax with Loss
    Softmax出力値から交差エントロピー誤差を計算

交差エントロピー誤差
    逆伝播が"yn - tn"というキレイな結果になるように設計されている
    恒等関数の損失関数に２乗和誤差を用いると、これの逆伝播も"yn - tn"となる

誤差逆伝搬による勾配の確認
    数値微分の結果を比較して正しく勾配が取得できていることを確認

