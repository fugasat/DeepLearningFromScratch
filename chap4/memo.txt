ニューラルネットワークを学習させるために何かしらの指標が必要
    損失関数を使う

損失関数
    主に二つの手法がある
    ・２乗和誤差
    ・交差エントロピー誤差
        -Σ(正解値 x log(NN出力値))の合計
        logを使う
        NN出力が正解に近いほど、誤差値が小さくなる
        (?)２乗和誤差よりもメリハリがでる？

重みパラメータを変えた時の影響を知りたい
    損失関数に対する微分で算出できる
        微分値がマイナス：重みパラメータを正方向へ変化させれば損失(関数)が減少
        微分値がプラス　：重みパラメータを負方向へ変化させれば損失(関数)が減少
        微分値が０：損失関数の値は変わらないので、重みパラメータの更新は不要

微分
    プログラムで算出する微分は数値微分と呼ぶ（誤差が発生する）

偏微分
    変数が２つ存在する(x0,x1)ケースの微分
    x0に対する偏微分はx1の値を固定にして求める（片方の変数は固定にしておく）

偏微分から勾配を求める
    全変数の偏微分をベクトルとしてまとめたものを勾配と呼ぶ
    各地点で低くなる方向を指す
        関数の値を最も減らす方向とも言える
    これは損失関数の値を減らす方向に使えるので重要

勾配法
    勾配の方向へ進むことによって関数の値を徐々に減らす方法

NNに対する勾配
    重みパラメータ => 偏微分の変数
    損失関数 => 微分を行う関数

勾配計算で使うデータは一部のデータをランダムでピックアップ（=ミニバッチ）
    確率的勾配降下法と呼ぶ

NNの学習フローは以下の繰り返しで実現
    ミニバッチ（テストデータ抽出）
    勾配計算
    重みパラメータ更新（バイアスも？）

学習結果の評価
    損失関数
        訓練データを対象とした結果なので、これでは汎化能力は分からない
    認識精度
        テストデータを使って認識精度の計算を行い、これで学習結果の評価を行う
        ミニバッチで抽出した訓練データを全て使い切ったときに精度を計算する（１エポック）

